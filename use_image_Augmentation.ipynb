{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxykJDDP2ha1"
      },
      "outputs": [],
      "source": [
        "#1.먼저 필요한 모듈들을 import 한다.\n",
        "\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import glob\n",
        "import cv2\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "import torchvision.models as models\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "#2. 엔비디아 그래픽 카드를 사용하고 있다면 device에 cuda가 나와야 gpu가 성공적으로 할당된 것이다.\n",
        "\n",
        "\n",
        "\n",
        "# 이것도 드라이버 버전, 파이토치 버전, 쿠다 버전의 호환이 각 버전마다 다르기 때문에 검색을 반드시 해서 참고해야 한다.\n",
        "\n",
        "# 성공적으로 gpu를 할당했으면 우리가 기본적으로 사용할 image size, epoch수 learning rate, batch_size, seed를 정한다.\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "CFG = {\n",
        "    'IMG_SIZE':224,\n",
        "    'EPOCHS':30,\n",
        "    'LEARNING_RATE':5e-4,\n",
        "    'BATCH_SIZE':32,\n",
        "    'SEED':41\n",
        "}\n",
        "# 3. 딥러닝에는 랜덤으로 작업하는 것이 많기 때문에 같은 결과를 얻기 위해서 최대한 seed를 고정한다.\n",
        "\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything(CFG['SEED']) # Seed 고정\n",
        "# 4. 경로에 있는 이미지의 주소를 전부 읽어와서 all_img_list에 리스트로 저장한다.\n",
        "\n",
        "# 이미지 주소에 label이 포함되어 있으므로 split 함수를 통해 label을 때어내서 df['label']에 저장한다.\n",
        "\n",
        "all_img_list = glob.glob('./train/*/*')\n",
        "df = pd.DataFrame(columns=['img_path', 'label'])\n",
        "df['img_path'] = all_img_list\n",
        "df['label'] = df['img_path'].apply(lambda x : str(x).split('\\\\')[1])\n",
        "5. 만들어진 df의 형태는 아래와같이 파일의 경로를 나타내는 img_path와 label을 나타내는 label로 이루어져 있다.\n",
        "\n",
        "df\n",
        "\n",
        "img_path\tlabel\n",
        "0\t./train\\가구수정\\0.png\t가구수정\n",
        "1\t./train\\가구수정\\1.png\t가구수정\n",
        "2\t./train\\가구수정\\10.png\t가구수정\n",
        "3\t./train\\가구수정\\11.png\t가구수정\n",
        "4\t./train\\가구수정\\2.png\t가구수정\n",
        "...\t...\t...\n",
        "3452\t./train\\훼손\\995.png\t훼손\n",
        "3453\t./train\\훼손\\996.png\t훼손\n",
        "3454\t./train\\훼손\\997.png\t훼손\n",
        "3455\t./train\\훼손\\998.png\t훼손\n",
        "3456\t./train\\훼손\\999.png\t훼손\n",
        "# 6.test error를 추정하기 위해 train set을 train과 validation set으로 나눈다.\n",
        "\n",
        "#     이후 label encoding을 통해 하자 유형을 숫자에 매핑한다.\n",
        "\n",
        "train, val, _, _ = train_test_split(df, df['label'], test_size=0.2, stratify=df['label'], random_state=CFG['SEED'])\n",
        "le = preprocessing.LabelEncoder()\n",
        "train['label'] = le.fit_transform(train['label'])\n",
        "val['label'] = le.transform(val['label'])\n",
        "# 7. 이미지 데이터를 다룰때는 CustomDataset이라는 class를 정의하고 사용을 하는데 여기서 중요한 것은 __getitem__이며 이미지를 한개씩 보면서 array형식으로 저장하고 이후에 정의할 transforms를 넣으면 적용이 되도록 하였다. 또한 label이 none이 아니면 image와 label을 동시에 반환하고 test셋에는 label이 없기 때문에 label이 없으면 image만 반환하게 하였다.\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, img_path_list, label_list, transforms=None):\n",
        "        self.img_path_list = img_path_list\n",
        "        self.label_list = label_list\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_path = self.img_path_list[index]\n",
        "\n",
        "        image = Image.open(img_path)\n",
        "        image = np.array(image)\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            image = self.transforms(image=image)['image']\n",
        "\n",
        "        if self.label_list is not None:\n",
        "            label = self.label_list[index]\n",
        "            return image, label\n",
        "        else:\n",
        "            return image\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_path_list)\n",
        "# 8. 다음은 이미지 증강기법이다. 이 대회에 주어진 이미지는 약 1000장 정도로 적은양의 데이터 이기 때문에 좌우반전, 크기조절, 상하반전, 밝기 조절 등을 통해서 같은 이미지를 확률적으로 변형을 시켜서 다양하게 학습할 수 있게 한다.\n",
        "\n",
        "train_transform = A.Compose([\n",
        "    A.RandomResizedCrop(CFG['IMG_SIZE'], CFG['IMG_SIZE'], scale=(0.2, 0.8)),\n",
        "    A.Transpose(p=0.5),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.5),\n",
        "    A.ShiftScaleRotate(p=0.5),\n",
        "    A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=20, val_shift_limit=20, p=0.5),\n",
        "    A.RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
        "    A.ChannelShuffle(),\n",
        "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0),\n",
        "    A.CoarseDropout(p=0.5),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "test_transform = A.Compose([\n",
        "                            A.Resize(CFG['IMG_SIZE'],CFG['IMG_SIZE']),\n",
        "                            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0),\n",
        "                            ToTensorV2()\n",
        "                            ])\n",
        "train_dataset = CustomDataset(train['img_path'].values, train['label'].values, train_transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
        "\n",
        "val_dataset = CustomDataset(val['img_path'].values, val['label'].values, test_transform)\n",
        "val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
        "# 9. 우리가 사용할 모델에 대해 작성한다. 이번에는 efficientnet_b4모델을 이용해서 트레이닝을 했다.\n",
        "\n",
        "# 그래픽 카드가 3080ti라 그래도 잘 될거라 생각했는데 vram 12gb로는 감당이 안돼서 더 큰 모델은 사용이 불가능 했다.\n",
        "\n",
        "class BaseModel(nn.Module):\n",
        "    def __init__(self, num_classes=len(le.classes_)):\n",
        "        super(BaseModel, self).__init__()\n",
        "        self.backbone = models.efficientnet_b4(pretrained=True)\n",
        "        self.backbone.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=0.3, inplace=True),\n",
        "            nn.Linear(in_features=1280, out_features=num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x)\n",
        "        return x\n",
        "# 10. 손실함수를 정의하고 모델을 훈련시킨다. 최종적으로  f1 score를 사용해 모델을 평가할 것이고\n",
        "\n",
        "#        손실계산은 crossEntropy를 활용했다.\n",
        "\n",
        "def train2(model, optimizer, train_loader, val_loader, scheduler, device):\n",
        "    model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "    best_score = 0\n",
        "    best_model = None\n",
        "\n",
        "    for epoch in range(1, CFG['EPOCHS']+1):\n",
        "        model.train()\n",
        "        train_loss = []\n",
        "        for imgs, labels in tqdm(iter(train_loader)):\n",
        "            imgs = imgs.float().to(device)\n",
        "            labels = labels.type(torch.LongTensor).to(device)      # ADDED .type(torch.LongTensor)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            output = model(imgs)\n",
        "            loss = criterion(output, labels)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss.append(loss.item())\n",
        "\n",
        "        _val_loss, _val_score = validation(model, criterion, val_loader, device)\n",
        "        _train_loss = np.mean(train_loss)\n",
        "        print(f'Epoch [{epoch}], Train Loss : [{_train_loss:.5f}] Val Loss : [{_val_loss:.5f}] Val Weighted F1 Score : [{_val_score:.5f}]')\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step(_val_score)\n",
        "\n",
        "        if best_score < _val_score:\n",
        "            best_score = _val_score\n",
        "            best_model = model\n",
        "\n",
        "    return best_model\n",
        "​\n",
        "\n",
        "def validation(model, criterion, val_loader, device):\n",
        "    model.eval()\n",
        "    val_loss = []\n",
        "    preds, true_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in tqdm(iter(val_loader)):\n",
        "            imgs = imgs.float().to(device)\n",
        "            labels = labels.type(torch.LongTensor).to(device)      # ADDED .type(torch.LongTensor)\n",
        "\n",
        "            pred = model(imgs)\n",
        "\n",
        "            loss = criterion(pred, labels)\n",
        "\n",
        "            preds += pred.argmax(1).detach().cpu().numpy().tolist()\n",
        "            true_labels += labels.detach().cpu().numpy().tolist()\n",
        "\n",
        "            val_loss.append(loss.item())\n",
        "\n",
        "        _val_loss = np.mean(val_loss)\n",
        "        _val_score = f1_score(true_labels, preds, average='weighted')\n",
        "\n",
        "    return _val_loss, _val_score\n",
        "# 11. 모델학습에 사용할 optimizer와 scheduler를 정의했다. Adam 옵티마이저를 사용하고 '\n",
        "\n",
        "#        ReduceLROnPlateau 스케줄러를 활용했다.\n",
        "\n",
        "model = BaseModel()\n",
        "model.eval()\n",
        "optimizer = torch.optim.Adam(params = model.parameters(), lr = CFG[\"LEARNING_RATE\"])\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2, threshold_mode='abs', min_lr=1e-8, verbose=True)\n",
        "\n",
        "infer_model = train2(model, optimizer, train_loader, val_loader, scheduler, device)\n",
        "# 12. 학습한 최고의 가중치를 경로에 저장해서 필요할 때 꺼낼 수 있게 한다.\n",
        "\n",
        "#        torch.cuda.empty_cache()를 통해 cuda에 남아있는 메모리를 지운다.\n",
        "\n",
        "torch.save(infer_model, 'C:\\\\Users\\\\82107\\\\Downloads\\\\open (2)\\\\b00_32_30.pt')\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "# 13. 테스트 데이터를 불러오고 예측을 진행한다.\n",
        "\n",
        "test = pd.read_csv('./test.csv')\n",
        "test_dataset0 = CustomDataset(test['img_path'].values, None, resize_transform(224,'test'))\n",
        "test_loader0 = DataLoader(test_dataset0, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
        "def inference(model, test_loader, device):\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    with torch.no_grad():\n",
        "        for imgs in tqdm(iter(test_loader)):\n",
        "            imgs = imgs.float().to(device)\n",
        "\n",
        "            pred = model(imgs)\n",
        "\n",
        "            preds += pred.argmax(1).detach().cpu().numpy().tolist()\n",
        "\n",
        "    preds = le.inverse_transform(preds)\n",
        "    return preds\n",
        "preds0 = inference(loaded_model0, test_loader0, device)\n",
        "# 14. 제출을 진행한다.\n",
        "\n",
        "#      처음에 그냥 제출을 했더니 0점이 나와서 당황했는데 이유를 살펴보니 파일 형식이 utf-8로 고정되어야 한다고  했고 또한   inverse_transform 으로 label 인코더를 풀어서 하면 안된다는 것을 알게 되어 직접 매칭을 해주었다.\n",
        "\n",
        "submit0 = pd.read_csv('./sample_submission.csv')\n",
        "submit0['label'] = preds0\n",
        "\n",
        "\n",
        "submit0.loc[submit0['label'] == '0', 'label'] = '가구수정'\n",
        "submit0.loc[submit0['label'] == '1', 'label'] = '걸레받이수정'\n",
        "submit0.loc[submit0['label'] == '2', 'label'] = '곰팡이'\n",
        "submit0.loc[submit0['label'] == '3', 'label'] = '꼬임'\n",
        "submit0.loc[submit0['label'] == '4', 'label'] = '녹오염'\n",
        "submit0.loc[submit0['label'] == '5', 'label'] = '들뜸'\n",
        "submit0.loc[submit0['label'] == '6', 'label'] = '면불량'\n",
        "submit0.loc[submit0['label'] == '7', 'label'] = '몰딩수정'\n",
        "submit0.loc[submit0['label'] == '8', 'label'] = '반점'\n",
        "submit0.loc[submit0['label'] == '9', 'label'] = '석고수정'\n",
        "submit0.loc[submit0['label'] == '10', 'label'] = '오염'\n",
        "submit0.loc[submit0['label'] == '11', 'label'] = '오타공'\n",
        "submit0.loc[submit0['label'] == '12', 'label'] = '울음'\n",
        "submit0.loc[submit0['label'] == '13', 'label'] = '이음부불량'\n",
        "submit0.loc[submit0['label'] == '14', 'label'] = '창틀,문틀수정'\n",
        "submit0.loc[submit0['label'] == '15', 'label'] = '터짐'\n",
        "submit0.loc[submit0['label'] == '16', 'label'] = '틈새과다'\n",
        "submit0.loc[submit0['label'] == '17', 'label'] = '피스'\n",
        "submit0.loc[submit0['label'] == '18', 'label'] = '훼손'\n",
        "submit0.to_csv('./baseline_submit100.csv', index=False)"
      ]
    }
  ]
}